import uvicorn
import socketio
import asyncio
import sys
import os
import base64
import numpy as np
import cv2
from typing import Dict, Any, Optional
import base64
import uuid
import asyncio

from pydub import AudioSegment
from pydub.effects import normalize as pydub_normalize

# ì»¤ìŠ¤í…€ ëª¨ë“ˆ
from core.router import Router
from core.model_loader import ModelContainer

try:
    import audioop_lts
    sys.modules["audioop"] = audioop_lts
except ImportError:
    pass

# í™˜ê²½ ì„¤ì •
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
PORT = int(os.getenv("PORT", 3000))

# ----------------------------------------------------------------
# 1. ì „ì—­ ëª¨ë¸ ë¡œë”© (Singleton)
# ----------------------------------------------------------------
# ì„œë²„ ì‹œì‘ ì‹œ ë”± í•œ ë²ˆë§Œ ë¬´ê±°ìš´ ëª¨ë¸ë“¤ì„ ë¡œë”©í•©ë‹ˆë‹¤.
global_models = ModelContainer.get_instance()

# ----------------------------------------------------------------
# 2. ì„œë²„ ë° ì„¸ì…˜ ì„¤ì •
# ----------------------------------------------------------------
sio = socketio.AsyncServer(async_mode='asgi', cors_allowed_origins='*')
app = socketio.ASGIApp(sio)

sessions: Dict[str, Router] = {}

# ----------------------------------------------------------------
# 3. í—¬í¼ í•¨ìˆ˜ (ì¤‘ë³µ ë¡œì§ ì œê±°)
# ----------------------------------------------------------------
def format_response_payload(response_data: Any) -> Dict[str, Any]:
    """
    Routerì˜ ë°˜í™˜ê°’ì„ ë¶„ì„í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ ê·œê²©(JSON)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    data, meta = None, None

    # (ë°ì´í„°, ë©”íƒ€ë°ì´í„°) íŠœí”Œ í˜•íƒœì¸ì§€ í™•ì¸
    if isinstance(response_data, (tuple, list)) and len(response_data) == 2:
        data, meta = response_data
    else:
        data = response_data

    # set íƒ€ì…ì€ JSON ì§ë ¬í™” ë¶ˆê°€í•˜ë¯€ë¡œ listë¡œ ë³€í™˜
    if isinstance(data, set):
        data = list(data)

    # ë©”íƒ€ë°ì´í„° ìœ ë¬´ì— ë”°ë¼ ì‘ë‹µ íƒ€ì… ê²°ì •
    msg_type = "confirm" if meta else "simple"
    
    return {
        "text": data,
        "type": msg_type,
        "meta": meta # í•„ìš”í•˜ë‹¤ë©´ ë©”íƒ€ë°ì´í„°ë„ í•¨ê»˜ ì „ì†¡
    }

def decode_image(base64_string: str) -> Optional[np.ndarray]:
    """
    Base64 ë¬¸ìì—´ì„ OpenCV ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    try:
        if ',' in base64_string:
            _, base64_data = base64_string.split(',', 1)
        else:
            base64_data = base64_string

        img_data = base64.b64decode(base64_data)
        nparr = np.frombuffer(img_data, np.uint8)
        return cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    except Exception as e:
        print(f"ğŸ–¼ ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {e}")
        return None

def get_or_create_router(sid: str) -> Optional[Router]:
    """
    ì„¸ì…˜ì„ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê±°ë‚˜, ì—†ìœ¼ë©´ ì¬ìƒì„±í•©ë‹ˆë‹¤.
    """
    if sid not in sessions:
        try:
            # [ì¤‘ìš”] ì¬ìƒì„± ì‹œì—ë„ ë°˜ë“œì‹œ ì „ì—­ ëª¨ë¸ì„ ì£¼ì…í•´ì•¼ í•©ë‹ˆë‹¤.
            sessions[sid] = Router(models=global_models)
        except Exception as e:
            print(f"ğŸš¨ Router ì¬ìƒì„± ì‹¤íŒ¨ ({sid}): {e}")
            return None
    return sessions[sid]


# ----------------------------------------------------------------
# 4. ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
# ----------------------------------------------------------------

@sio.event
async def connect(sid, environ):
    print(f"âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨: {sid}")
    get_or_create_router(sid)

@sio.event
async def disconnect(sid):
    print(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠê¹€: {sid}")
    sessions.pop(sid, None) # ì•ˆì „í•œ ì‚­ì œ

@sio.on('command')
async def handle_command(sid, data):
    """ ì•± -> ì„œë²„: í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ """
    print(f"ğŸ“© ìˆ˜ì‹  ({sid}): {data}")
    user_text = data.get('text', '')
    
    router = get_or_create_router(sid)
    if not router:
        await sio.emit('command-response', {"text": "ì„œë²„ ì´ˆê¸°í™” ì˜¤ë¥˜", "type": "error"}, to=sid)
        return

    try:
        # AI ì¶”ë¡  (ë¹„ë™ê¸° ìŠ¤ë ˆë“œ ì‹¤í–‰)
        response_data = await asyncio.to_thread(router.handle, user_text)
        
        # ì‘ë‹µ í¬ë§·íŒ… ë° ì „ì†¡
        payload = format_response_payload(response_data)
        await sio.emit('command-response', payload, to=sid)
        print(f"ğŸ“¤ ì „ì†¡: {payload}")

    except Exception as e:
        print(f"ğŸš¨ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
        await sio.emit('command-response', {"text": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "type": "error"}, to=sid)


@sio.on('action-confirm')
async def handle_action_confirm(sid, data):
    """ ì•± -> ì„œë²„: [ë„¤] ë²„íŠ¼ í´ë¦­ """
    print(f"ğŸ”˜ ë²„íŠ¼ í´ë¦­ ìˆ˜ì‹  (YES): {data}")
    
    router = get_or_create_router(sid)
    if not router:
        return

    try:
        # Decision ë¡œì§ ìˆ˜í–‰ ("ë„¤"ë¼ëŠ” í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬)
        response_data = await asyncio.to_thread(router.handle, "ë„¤")
        
        # ì‘ë‹µ í¬ë§·íŒ… ë° ì „ì†¡ (handle_commandì™€ ë™ì¼ ë¡œì§ ì‚¬ìš©)
        payload = format_response_payload(response_data)
        await sio.emit('command-response', payload, to=sid)
        print(f"ğŸ“¤ ì‹¤í–‰ ì™„ë£Œ ì‘ë‹µ ì „ì†¡: {payload}")

    except Exception as e:
        print(f"ğŸš¨ ì‹¤í–‰ ì¤‘ ì—ëŸ¬: {e}")
        await sio.emit('command-response', {"text": "ì‹¤í–‰ ì˜¤ë¥˜ ë°œìƒ", "type": "error"}, to=sid)

@sio.on('audio-upload')
async def handle_audio_upload(sid, data):
    """
    ì•± -> ì„œë²„: ìŒì„± ìˆ˜ì‹  -> [ì „ì²˜ë¦¬] -> Whisper STT -> Router -> ì‘ë‹µ
    """
    print(f"ğŸ¤ ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  ({sid})")
    
    router = get_or_create_router(sid)
    if not router:
        return

    # ì„ì‹œ íŒŒì¼ ê²½ë¡œ ë³€ìˆ˜ë“¤ ì´ˆê¸°í™”
    raw_filename = None
    processed_filename = None

    try:
        # 1. ë°ì´í„° íŒŒì‹±
        b64_string = data.get('audioData')
        file_ext = data.get('format', 'm4a')
        user_id = data.get('userId', 'unknown')

        # Base64 ë””ì½”ë”©
        audio_bytes = base64.b64decode(b64_string)
        
        if not os.path.exists('uploads'):
            os.makedirs('uploads')
            
        # 2. ì›ë³¸ íŒŒì¼ ì €ì¥ (.m4a)
        raw_filename = f"uploads/{user_id}_{uuid.uuid4()}.{file_ext}"
        with open(raw_filename, "wb") as f:
            f.write(audio_bytes)
            
        print(f"ğŸ’¾ ì›ë³¸ ì €ì¥ ì™„ë£Œ: {raw_filename}")

        # =======================================================
        # [âœ¨ ì¶”ê°€ë¨] 3. ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ (Preprocessing)
        # Whisperê°€ ê°€ì¥ ì¢‹ì•„í•˜ëŠ” í˜•íƒœ(16kHz, Mono, Normalized)ë¡œ ë³€í™˜
        # =======================================================
        def preprocess_audio():
            print("ğŸ›ï¸ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì¤‘... (Resample & Normalize)")
            
            # ì›ë³¸ ë¡œë“œ
            audio = AudioSegment.from_file(raw_filename, format=file_ext)
            
            # (1) ëª¨ë…¸ë¡œ ë³€í™˜ (ì±„ë„ 1ê°œ)
            audio = audio.set_channels(1)
            
            # (2) ì£¼íŒŒìˆ˜ 16000Hzë¡œ ë³€ê²½ (Whisper ë‚´ë¶€ í‘œì¤€)
            audio = audio.set_frame_rate(16000)
            
            # (3) ë³¼ë¥¨ ì •ê·œí™” (ì‘ì€ ëª©ì†Œë¦¬ ì¦í­)
            audio = pydub_normalize(audio)
            
            # ì „ì²˜ë¦¬ëœ íŒŒì¼ëª… ìƒì„± (.wav)
            new_filename = raw_filename.replace(f".{file_ext}", "_processed.wav")
            
            # wav í¬ë§·ìœ¼ë¡œ ì €ì¥
            audio.export(new_filename, format="wav")
            return new_filename

        # ì „ì²˜ë¦¬ ì‹¤í–‰ (ë™ê¸° ì‘ì—…ì´ë¯€ë¡œ ìŠ¤ë ˆë“œë¡œ ë¶„ë¦¬ ê¶Œì¥)
        processed_filename = await asyncio.to_thread(preprocess_audio)
        print(f"âœ¨ ì „ì²˜ë¦¬ ì™„ë£Œ: {processed_filename}")

        # =======================================================
        # 4. Whisper STT ë³€í™˜
        # =======================================================
        print("ğŸ‘‚ Whisper ì¸ì‹ ì¤‘...")
        stt_model = global_models.stt_model
        
        def transcribe_audio():
            # [ì¤‘ìš”] ì›ë³¸ ëŒ€ì‹  'ì „ì²˜ë¦¬ëœ wav íŒŒì¼'ì„ ë„£ìŠµë‹ˆë‹¤.
            # beam_size=5: ì •í™•ë„ë¥¼ ìœ„í•´ íƒìƒ‰ í­ì„ ë„“í˜ (ê¸°ë³¸ê°’ 1ë³´ë‹¤ ëŠë¦¬ì§€ë§Œ ì •í™•í•¨)
            return stt_model.transcribe(
                processed_filename, 
                language="ko", 
                fp16=False,
                beam_size=5,
                initial_prompt="ê±´ê°• ìƒë‹´, ëª¸ ìƒíƒœ, í—ˆì•½ ì²´ì§ˆ, ë³‘ì› ì§„ë£Œì— ëŒ€í•œ ëŒ€í™”ì…ë‹ˆë‹¤."
            )

        result = await asyncio.to_thread(transcribe_audio)
        recognized_text = result['text'].strip()
        
        print(f"ğŸ—£ï¸ ì¸ì‹ëœ í…ìŠ¤íŠ¸: \"{recognized_text}\"")

        # -------------------------------------------------------
        # 5. ì‹¤íŒ¨ ì²˜ë¦¬ ë° ì‚¬ìš©ì í”¼ë“œë°± ì „ì†¡
        # -------------------------------------------------------
        if not recognized_text:
            await sio.emit('command-response', {"text": "ìŒì„±ì´ ë„ˆë¬´ ì‘ê±°ë‚˜ ë“¤ë¦¬ì§€ ì•Šì•˜ì–´ìš”.", "type": "simple"}, to=sid)
        else:
            # ì¸ì‹ ì„±ê³µ ì‹œ, ì•±ì— ë‚´ ë§ ë¨¼ì € ë„ì›Œì£¼ê¸°
            await sio.emit('user-speech', {'text': recognized_text}, to=sid)

            # 6. Router ì‹¤í–‰
            response_data = await asyncio.to_thread(router.handle, recognized_text)
            
            # 7. ìµœì¢… ì‘ë‹µ
            payload = format_response_payload(response_data)
            await sio.emit('command-response', payload, to=sid)
            print(f"ğŸ“¤ ì‘ë‹µ ì „ì†¡: {payload}")

    except Exception as e:
        print(f"ğŸš¨ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
        await sio.emit('command-response', {"text": "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "type": "error"}, to=sid)
    
    finally:
        # 8. [ì²­ì†Œ] ì„ì‹œ íŒŒì¼ë“¤ ì‚­ì œ (ìš©ëŸ‰ ê´€ë¦¬)
        try:
            if raw_filename and os.path.exists(raw_filename):
                os.remove(raw_filename)
            if processed_filename and os.path.exists(processed_filename):
                os.remove(processed_filename)
        except Exception as cleanup_error:
            print(f"ğŸ§¹ íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {cleanup_error}")

@sio.on('identify-face')
async def handle_identify_face(sid, base64_image):
    """ Expo ì•±ì˜ 'identify-face' ì´ë²¤íŠ¸ """
    print(f"ğŸ“¸ {sid} ì´ë¯¸ì§€ ìˆ˜ì‹  ({len(base64_image)} bytes)")

    try:
        # ì´ë¯¸ì§€ ë””ì½”ë”© í—¬í¼ ì‚¬ìš©
        img = await asyncio.to_thread(decode_image, base64_image)
        
        if img is None:
            await sio.emit('auth-fail', {"reason": "image_decode_error"}, to=sid)
            return

        # ... (ì–¼êµ´ ì¸ì‹ ë¡œì§ ì‹œë®¬ë ˆì´ì…˜) ...
        # ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ img ë³€ìˆ˜ë¥¼ face_recognition ëª¨ë¸ì— ë„˜ê¹ë‹ˆë‹¤.
        await asyncio.sleep(0.5) 
        user = {"id": "p123", "name": "ê¹€ë¸”ë¼"}

        await sio.emit('auth-success', user, to=sid)
        print(f"âœ… ì¸ì¦ ì„±ê³µ: {user['name']}")

    except Exception as e:
        print(f"ğŸš¨ ì¸ì¦ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        await sio.emit('auth-fail', to=sid)

if __name__ == "__main__":
    print(f"ğŸš€ AI Router ì„œë²„ ì‹œì‘ (Port: {PORT})")
    uvicorn.run(app, host="0.0.0.0", port=PORT)