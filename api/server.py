import uvicorn
import socketio
import asyncio
import sys
import os
import base64
import numpy as np
import cv2
from typing import Dict, Any, Optional
import uuid
import librosa
import torch

from pydub import AudioSegment
from pydub.effects import normalize as pydub_normalize

# ì»¤ìŠ¤í…€ ëª¨ë“ˆ (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ê°€ì •)
from core.router import Router
from core.model_loader import ModelContainer

try:
    import audioop_lts
    sys.modules["audioop"] = audioop_lts
except ImportError:
    pass

# í™˜ê²½ ì„¤ì •
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
PORT = int(os.getenv("PORT", 3000))
HEALTH_KEYWORDS = ["ë³‘ì›", "ì§„ë£Œ", "ì˜ì‚¬", "ê°„í˜¸ì‚¬", "ì¦ìƒ", "ì•„íŒŒ", "ì˜ˆì•½", "ìƒë‹´", "ê±´ê°•", "ìˆ˜ìˆ ", "ê²€ì§„", "ì•½", "ë³µìš©"]
# [ì‹ ê·œ] ë¹„ìƒ ì •ì§€ ê°ì§€ í‚¤ì›Œë“œ
EMERGENCY_KEYWORDS = ["ì •ì§€", "ë©ˆì¶°", "ì„œë¼", "ìŠ¤í†±", "STOP", "SOS", "ë¹„ìƒ"]

# ----------------------------------------------------------------
# 1. ì „ì—­ ëª¨ë¸ ë¡œë”© (Singleton)
# ----------------------------------------------------------------
# ì„œë²„ ì‹œì‘ ì‹œ ë”± í•œ ë²ˆë§Œ ë¬´ê±°ìš´ ëª¨ë¸ë“¤ì„ ë¡œë”©í•©ë‹ˆë‹¤.
global_models = ModelContainer.get_instance()

# ----------------------------------------------------------------
# 2. ì„œë²„ ë° ì„¸ì…˜ ì„¤ì •
# ----------------------------------------------------------------
sio = socketio.AsyncServer(async_mode='asgi', cors_allowed_origins='*')
app = socketio.ASGIApp(sio)

sessions: Dict[str, Router] = {}

# ----------------------------------------------------------------
# 3. í—¬í¼ í•¨ìˆ˜
# ----------------------------------------------------------------
def format_response_payload(response_data: Any) -> Dict[str, Any]:
    """ Routerì˜ ë°˜í™˜ê°’ì„ ë¶„ì„í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ ê·œê²©(JSON)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. """
    data, meta = None, None

    if isinstance(response_data, (tuple, list)) and len(response_data) == 2:
        data, meta = response_data
    else:
        data = response_data

    if isinstance(data, set):
        data = list(data)

    msg_type = "confirm" if meta else "simple"
    
    return {
        "text": data,
        "type": msg_type,
        "meta": meta
    }

def decode_image(base64_string: str) -> Optional[np.ndarray]:
    try:
        if ',' in base64_string:
            _, base64_data = base64_string.split(',', 1)
        else:
            base64_data = base64_string

        img_data = base64.b64decode(base64_data)
        nparr = np.frombuffer(img_data, np.uint8)
        return cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    except Exception as e:
        print(f"ğŸ–¼ ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {e}")
        return None

def get_or_create_router(sid: str) -> Optional[Router]:
    if sid not in sessions:
        try:
            sessions[sid] = Router(models=global_models)
        except Exception as e:
            print(f"ğŸš¨ Router ì¬ìƒì„± ì‹¤íŒ¨ ({sid}): {e}")
            return None
    return sessions[sid]

# ----------------------------------------------------------------
# 4. ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
# ----------------------------------------------------------------

@sio.event
async def connect(sid, environ):
    print(f"âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨: {sid}")
    get_or_create_router(sid)

@sio.event
async def disconnect(sid):
    print(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠê¹€: {sid}")
    sessions.pop(sid, None)

# [ì‹ ê·œ] ë¹„ìƒ ì •ì§€ í•¸ë“¤ëŸ¬ (ë²„íŠ¼ í´ë¦­ ì‹œ í˜¸ì¶œ)
@sio.on('pause')
async def handle_pause(sid, data):
    """ ì•± -> ì„œë²„: ë¹„ìƒ ì •ì§€ ë²„íŠ¼ í´ë¦­ """
    user_id = data.get('userId', 'unknown')
    print(f"\n[!!! EMERGENCY !!!] ğŸš¨ ë¹„ìƒ ì •ì§€ ìš”ì²­ë¨ ({data})")
    router = get_or_create_router(sid)
    user_text = data.get('text', '')

    # AI ì¶”ë¡  (ë¹„ë™ê¸° ìŠ¤ë ˆë“œ ì‹¤í–‰)
    await asyncio.to_thread(router.handle, user_text)

    # í´ë¼ì´ì–¸íŠ¸ì— ì •ì§€ í™•ì¸ ì‘ë‹µ ì „ì†¡
    await sio.emit('command-response', {
        "text": "ë¹„ìƒ ì •ì§€ ëª…ë ¹ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë¡œë´‡ì„ ì¦‰ì‹œ ì •ì§€í•©ë‹ˆë‹¤.",
        "type": "simple",
        "meta": {"status": "stopped", "emergency": True}
    }, to=sid)

@sio.on('command')
async def handle_command(sid, data):
    """ ì•± -> ì„œë²„: í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ """
    print(f"ğŸ“© ìˆ˜ì‹  ({sid}): {data}")
    user_text = data.get('text', '')
    
    # [ìˆ˜ì •] í…ìŠ¤íŠ¸ ëª…ë ¹ì—ì„œ ë¹„ìƒ ì •ì§€ í‚¤ì›Œë“œ ìš°ì„  ê°ì§€
    # "ë©ˆì¶°", "ì •ì§€" ë“±ì˜ ë§ì´ ë“¤ë¦¬ë©´ AI ì¶”ë¡  ì—†ì´ ë°”ë¡œ ì •ì§€ì‹œí‚µë‹ˆë‹¤.
    # if any(kw in user_text for kw in EMERGENCY_KEYWORDS):
    #     print(f"ğŸ›‘ í…ìŠ¤íŠ¸ì—ì„œ ë¹„ìƒ ì •ì§€ í‚¤ì›Œë“œ ê°ì§€: {user_text}")
    #     await execute_emergency_stop(sid, data.get('userId', 'voice'))
    #     return

    router = get_or_create_router(sid)
    if not router:
        await sio.emit('command-response', {"text": "ì„œë²„ ì´ˆê¸°í™” ì˜¤ë¥˜", "type": "error"}, to=sid)
        return

    try:
        # AI ì¶”ë¡  (ë¹„ë™ê¸° ìŠ¤ë ˆë“œ ì‹¤í–‰)
        response_data = await asyncio.to_thread(router.handle, user_text)
        
        # ì‘ë‹µ í¬ë§·íŒ… ë° ì „ì†¡
        payload = format_response_payload(response_data)
        await sio.emit('command-response', payload, to=sid)
        print(f"ğŸ“¤ ì „ì†¡: {payload}")

    except Exception as e:
        print(f"ğŸš¨ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
        await sio.emit('command-response', {"text": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "type": "error"}, to=sid)

@sio.on('action-confirm')
async def handle_action_confirm(sid, data):
    """ ì•± -> ì„œë²„: [ë„¤] ë²„íŠ¼ í´ë¦­ """
    print(f"ğŸ”˜ ë²„íŠ¼ í´ë¦­ ìˆ˜ì‹  (YES): {data}")
    
    router = get_or_create_router(sid)
    if not router:
        return

    try:
        # Decision ë¡œì§ ìˆ˜í–‰
        response_data = await asyncio.to_thread(router.handle, "ë„¤")
        payload = format_response_payload(response_data)
        await sio.emit('command-response', payload, to=sid)
        print(f"ğŸ“¤ ì‹¤í–‰ ì™„ë£Œ ì‘ë‹µ ì „ì†¡: {payload}")

    except Exception as e:
        print(f"ğŸš¨ ì‹¤í–‰ ì¤‘ ì—ëŸ¬: {e}")
        await sio.emit('command-response', {"text": "ì‹¤í–‰ ì˜¤ë¥˜ ë°œìƒ", "type": "error"}, to=sid)

@sio.on('audio-upload')
async def handle_audio_upload(sid, data):
    """
    ì•± -> ì„œë²„: ìˆ˜ì‹  -> ì „ì²˜ë¦¬ -> [í•˜ì´ë¸Œë¦¬ë“œ STT] -> Router -> ì‘ë‹µ
    """
    print(f"ğŸ¤ ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  ({sid})")
    
    router = get_or_create_router(sid)
    if not router:
        return

    raw_filename = None
    processed_filename = None

    try:
        # 1. ë°ì´í„° íŒŒì‹± ë° íŒŒì¼ ì €ì¥
        b64_string = data.get('audioData')
        file_ext = data.get('format', 'm4a')
        user_id = data.get('userId', 'unknown')

        audio_bytes = base64.b64decode(b64_string)
        
        if not os.path.exists('uploads'):
            os.makedirs('uploads')
            
        raw_filename = f"uploads/{user_id}_{uuid.uuid4()}.{file_ext}"
        with open(raw_filename, "wb") as f:
            f.write(audio_bytes)
            
        print(f"ğŸ’¾ ì›ë³¸ ì €ì¥ ì™„ë£Œ: {raw_filename}")

        # 2. ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
        def preprocess_audio():
            print("ğŸ›ï¸ ì „ì²˜ë¦¬: Resample(16k) & Normalize")
            audio = AudioSegment.from_file(raw_filename, format=file_ext)
            audio = audio.set_channels(1)       
            audio = audio.set_frame_rate(16000) 
            audio = pydub_normalize(audio)      
            
            new_filename = raw_filename.replace(f".{file_ext}", "_processed.wav")
            audio.export(new_filename, format="wav")
            return new_filename

        processed_filename = await asyncio.to_thread(preprocess_audio)
        print(f"âœ¨ ì „ì²˜ë¦¬ ì™„ë£Œ: {processed_filename}")

        # 3. [1ì°¨] ì¼ë°˜ Whisper ì¸ì‹
        print("ğŸ‘‚ [1ë‹¨ê³„] ì¼ë°˜ ëª¨ë¸ ì¸ì‹ ì¤‘...")
        models = global_models 

        def transcribe_std():
            result = models.stt_model.transcribe(
                processed_filename, 
                language="ko", 
                fp16=False,
                beam_size=5,
                initial_prompt="ê±´ê°• ìƒë‹´, ëª¸ ìƒíƒœ, í—ˆì•½ ì²´ì§ˆ, ë³‘ì› ì§„ë£Œ, ë¹„ìƒ ì •ì§€, ë©ˆì¶°ì— ëŒ€í•œ ëŒ€í™”ì…ë‹ˆë‹¤."
            )
            text = result['text'].strip()
            score = -10.0
            if result.get('segments'):
                score = result['segments'][0].get('avg_logprob', -10.0)
            return text, score

        text_std, score_std = await asyncio.to_thread(transcribe_std)
        print(f"ğŸ—£ï¸ [1ì°¨ ê²°ê³¼] '{text_std}' (í™•ì‹ ë„: {score_std:.2f})")

        # 4. [íŒë‹¨] êµ¬ìŒì¥ì•  ëª¨ë¸ ê°€ë™ ì—¬ë¶€ ê²°ì •
        use_dys_model = False
        if score_std < -0.7:
            use_dys_model = True
        elif len(text_std) < 3:
            use_dys_model = True

        for kw in HEALTH_KEYWORDS:
            if kw in text_std:
                use_dys_model = False
                break
        
        # [ì¶”ê°€] ë¹„ìƒ ì •ì§€ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ êµ¬ìŒì¥ì•  ëª¨ë¸ ìƒëµí•˜ê³  ë°”ë¡œ ì±„íƒ (ë¹ ë¥¸ ë°˜ì‘)
        for kw in EMERGENCY_KEYWORDS:
            if kw in text_std:
                use_dys_model = False
                print(f"ğŸ›‘ ë¹„ìƒ ì •ì§€ í‚¤ì›Œë“œ('{kw}') ê°ì§€ -> ì¼ë°˜ ëª¨ë¸ ê²°ê³¼ ì¦‰ì‹œ ì‚¬ìš©")
                break

        final_text = text_std

        # 5. [2ì°¨] êµ¬ìŒì¥ì•  íŠ¹í™” ëª¨ë¸ (í•„ìš” ì‹œ ì‹¤í–‰)
        if use_dys_model:
            print("ğŸš€ [2ë‹¨ê³„] êµ¬ìŒì¥ì•  íŠ¹í™” ëª¨ë¸ ê°€ë™")

            def transcribe_dys():
                audio_array, _ = librosa.load(processed_filename, sr=16000)
                inputs = models.dys_processor(
                    audio_array, 
                    sampling_rate=16000, 
                    return_tensors="pt"
                ).input_features.to(models.device)

                with torch.no_grad():
                    generated_ids = models.dys_model.generate(inputs, language="korean")

                transcription = models.dys_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                return transcription.strip()

            text_dys = await asyncio.to_thread(transcribe_dys)
            print(f"ğŸ—£ï¸ [2ì°¨ ê²°ê³¼] '{text_dys}'")
            if text_dys:
                final_text = text_dys

        # 6. [í›„ì²˜ë¦¬] í…ìŠ¤íŠ¸ êµì •
        if "í™”ì•½" in final_text:
            final_text = final_text.replace("í™”ì•½", "í—ˆì•½")

        print(f"âœ… ìµœì¢… í™•ì •: \"{final_text}\"")

        # 7. ì‘ë‹µ ì²˜ë¦¬
        if not final_text:
            await sio.emit('command-response', {"text": "ì˜ ë“£ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.", "type": "simple"}, to=sid)
            return

        # ì•±ì— ë‚´ ë§ ë¨¼ì € ë„ìš°ê¸°
        await sio.emit('user-speech', {'text': final_text}, to=sid)

        # [ìˆ˜ì •] ìŒì„± ì¸ì‹ ê²°ê³¼ì—ì„œë„ ë¹„ìƒ ì •ì§€ ê°ì§€
        if any(kw in final_text for kw in EMERGENCY_KEYWORDS):
            print(f"ğŸ›‘ ìŒì„± ëª…ë ¹ì—ì„œ ë¹„ìƒ ì •ì§€ ê°ì§€: {final_text}")
            await execute_emergency_stop(sid, user_id)
            return

        # ì¼ë°˜ ëª…ë ¹ -> Router ì‹¤í–‰
        response_data = await asyncio.to_thread(router.handle, final_text)
        
        payload = format_response_payload(response_data)
        await sio.emit('command-response', payload, to=sid)
        print(f"ğŸ“¤ ì‘ë‹µ ì „ì†¡: {payload}")

    except Exception as e:
        print(f"ğŸš¨ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()
        await sio.emit('command-response', {"text": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "type": "error"}, to=sid)
    
    finally:
        try:
            if raw_filename and os.path.exists(raw_filename):
                os.remove(raw_filename)
            if processed_filename and os.path.exists(processed_filename):
                os.remove(processed_filename)
        except Exception:
            pass

@sio.on('identify-face')
async def handle_identify_face(sid, base64_image):
    """ Expo ì•±ì˜ 'identify-face' ì´ë²¤íŠ¸ """
    print(f"ğŸ“¸ {sid} ì´ë¯¸ì§€ ìˆ˜ì‹  ({len(base64_image)} bytes)")

    try:
        img = await asyncio.to_thread(decode_image, base64_image)
        if img is None:
            await sio.emit('auth-fail', {"reason": "image_decode_error"}, to=sid)
            return

        # ì–¼êµ´ ì¸ì‹ ë¡œì§ (ì‹œë®¬ë ˆì´ì…˜)
        await asyncio.sleep(0.5) 
        user = {"id": "p123", "name": "ê¹€ë¸”ë¼"}

        await sio.emit('auth-success', user, to=sid)
        print(f"âœ… ì¸ì¦ ì„±ê³µ: {user['name']}")

    except Exception as e:
        print(f"ğŸš¨ ì¸ì¦ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        await sio.emit('auth-fail', to=sid)

if __name__ == "__main__":
    print(f"ğŸš€ AI Router ì„œë²„ ì‹œì‘ (Port: {PORT})")
    uvicorn.run(app, host="0.0.0.0", port=PORT)