import uvicorn
import socketio
import asyncio
import sys
import os
import base64
import numpy as np
import cv2
import time
from typing import Dict, Any, Optional
import uuid
import librosa 
import torch
from contextlib import nullcontext
import tempfile

from pydub import AudioSegment
from pydub.effects import normalize as pydub_normalize

# ì»¤ìŠ¤í…€ ëª¨ë“ˆ
from core.router import Router
from core.model_loader import ModelContainer

try:
    import audioop_lts
    sys.modules["audioop"] = audioop_lts
except ImportError:
    pass

# í™˜ê²½ ì„¤ì •
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
os.environ["TOKENIZERS_PARALLELISM"] = "false"

PORT = int(os.getenv("PORT", 3000))

# [ìˆ˜ì •] ë‹¤êµ­ì–´ í‚¤ì›Œë“œ ë° ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì •ì˜
KEYWORDS = {
    "ko": {
        "health": ["ë³‘ì›", "ì§„ë£Œ", "ì˜ì‚¬", "ê°„í˜¸ì‚¬", "ì¦ìƒ", "ì•„íŒŒ", "ì˜ˆì•½", "ìƒë‹´", "ê±´ê°•", "ìˆ˜ìˆ ", "ê²€ì§„", "ì•½", "ë³µìš©"],
        "emergency": ["ì •ì§€", "ë©ˆì¶°", "ì„œë¼", "ìŠ¤í†±", "STOP", "SOS", "ë¹„ìƒ"],
        "whisper_lang": "korean"
    },
    "en": {
        "health": ["hospital", "doctor", "nurse", "symptom", "pain", "hurt", "appointment", "consult", "health", "surgery", "checkup", "medicine", "pill"],
        "emergency": ["stop", "halt", "freeze", "emergency", "sos", "help"],
        "whisper_lang": "english"
    }
}

SYSTEM_MESSAGES = {
    "ko": {
        "emergency_stop": "ë¹„ìƒ ì •ì§€í•©ë‹ˆë‹¤.",
        "emergency_ack": "ë¹„ìƒ ì •ì§€ ëª…ë ¹ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë¡œë´‡ì„ ì¦‰ì‹œ ì •ì§€í•©ë‹ˆë‹¤.",
        "server_error": "ì„œë²„ ì´ˆê¸°í™” ì˜¤ë¥˜",
        "process_error": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
        "exec_error": "ì‹¤í–‰ ì˜¤ë¥˜ ë°œìƒ",
        "not_heard": "ì˜ ë“£ì§€ ëª»í–ˆì–´ìš”.",
        "decode_error": "ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨"
    },
    "en": {
        "emergency_stop": "Initiating emergency stop.",
        "emergency_ack": "Emergency stop command received. Stopping robot immediately.",
        "server_error": "Server initialization error",
        "process_error": "Processing error",
        "exec_error": "Execution error",
        "not_heard": "I couldn't hear you clearly.",
        "decode_error": "Image decode failed"
    }
}

# ----------------------------------------------------------------
# ì„±ëŠ¥ ì¸¡ì • ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤
# ----------------------------------------------------------------
class PerformanceTimer:
    def __init__(self, task_name: str):
        self.task_name = task_name
        self.start_time = 0

    def __enter__(self):
        self.start_time = time.perf_counter()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        elapsed = (time.perf_counter() - self.start_time) * 1000
        status = "âŒ ì‹¤íŒ¨" if exc_type else "âœ… ì™„ë£Œ"
        print(f"â±ï¸ [Perf] [{self.task_name}] {status} | ì†Œìš”ì‹œê°„: {elapsed:.2f}ms")

# ----------------------------------------------------------------
# 1. ì „ì—­ ëª¨ë¸ ë¡œë”© (Singleton)
# ----------------------------------------------------------------
global_models = ModelContainer.get_instance()

# ----------------------------------------------------------------
# 2. ì„œë²„ ë° ì„¸ì…˜ ì„¤ì •
# ----------------------------------------------------------------
sio = socketio.AsyncServer(async_mode='asgi', cors_allowed_origins='*')
app = socketio.ASGIApp(sio)

sessions: Dict[str, Router] = {}

# ----------------------------------------------------------------
# 3. í—¬í¼ í•¨ìˆ˜
# ----------------------------------------------------------------
def format_response_payload(response_data: Any) -> Dict[str, Any]:
    data, meta = None, None
    if isinstance(response_data, (tuple, list)) and len(response_data) == 2:
        data, meta = response_data
    else:
        data = response_data

    if isinstance(data, set):
        data = list(data)

    msg_type = "confirm" if meta else "simple"
    return {"text": data, "type": msg_type, "meta": meta}

def decode_image(base64_string: str) -> Optional[np.ndarray]:
    try:
        if ',' in base64_string:
            _, base64_data = base64_string.split(',', 1)
        else:
            base64_data = base64_string
        img_data = base64.b64decode(base64_data)
        nparr = np.frombuffer(img_data, np.uint8)
        return cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    except Exception as e:
        print(f"ğŸ–¼ ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {e}")
        return None

def get_or_create_router(sid: str) -> Optional[Router]:
    if sid not in sessions:
        try:
            with PerformanceTimer(f"Router ìƒì„± ({sid})"):
                sessions[sid] = Router(models=global_models)
        except Exception as e:
            print(f"ğŸš¨ Router ì¬ìƒì„± ì‹¤íŒ¨ ({sid}): {e}")
            return None
    return sessions[sid]

# [ìˆ˜ì •] ì–¸ì–´ë³„ ë©”ì‹œì§€ ì²˜ë¦¬
async def execute_emergency_stop(sid, user_id, lang="ko"):
    print(f"ğŸ›‘ [EMERGENCY] ë¡œë´‡ ì •ì§€ ì‹¤í–‰: User={user_id}, Lang={lang}")
    msg = SYSTEM_MESSAGES.get(lang, SYSTEM_MESSAGES["ko"])["emergency_stop"]
    
    await sio.emit('command-response', {
        "text": msg, 
        "type": "simple",
        "meta": {"emergency": True}
    }, to=sid)

def build_prompt_with_lang(text: str, lang: str) -> str:
    """ì–¸ì–´ ì„¤ì •ì— ë”°ë¼ Routerì— ì „ë‹¬í•  í…ìŠ¤íŠ¸ ê°€ê³µ"""
    if lang == 'en':
        return f"{text} (Please respond in English)"
    return text

# ----------------------------------------------------------------
# 4. ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
# ----------------------------------------------------------------

@sio.event
async def connect(sid, environ):
    print(f"âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨: {sid}")
    get_or_create_router(sid)

@sio.event
async def disconnect(sid):
    print(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠê¹€: {sid}")
    sessions.pop(sid, None)

@sio.on('pause')
async def handle_pause(sid, data):
    print(f"\n[!!! EMERGENCY !!!] ğŸš¨ ë¹„ìƒ ì •ì§€ ìš”ì²­ë¨ ({data})")
    router = get_or_create_router(sid)
    
    user_text = data.get('text', '')
    lang = data.get('lang', 'ko') 
    
    sys_msg = SYSTEM_MESSAGES.get(lang, SYSTEM_MESSAGES["ko"])

    with PerformanceTimer("ë¹„ìƒ ì •ì§€ ì²˜ë¦¬"):
        # RouterëŠ” Pause ì²˜ë¦¬ì— ì–¸ì–´ê°€ í•„ìš” ì—†ì„ ìˆ˜ ìˆì§€ë§Œ, í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ì „ë‹¬ ë¡œì§ ìœ ì§€
        await asyncio.to_thread(router.handle, user_text)
    
    await sio.emit('command-response', {
        "text": sys_msg["emergency_ack"],
        "type": "simple",
        "meta": {"status": "stopped", "emergency": True}
    }, to=sid)

@sio.on('command')
async def handle_command(sid, data):
    print(f"ğŸ“© ìˆ˜ì‹  ({sid}): {data}")
    user_text = data.get('text', '')
    lang = data.get('lang', 'ko') 
    sys_msg = SYSTEM_MESSAGES.get(lang, SYSTEM_MESSAGES["ko"])

    router = get_or_create_router(sid)
    if not router:
        await sio.emit('command-response', {"text": sys_msg["server_error"], "type": "error"}, to=sid)
        return

    try:
        with PerformanceTimer("í…ìŠ¤íŠ¸ ëª…ë ¹ ì²˜ë¦¬ (Router)"):
            # [í•µì‹¬ ìˆ˜ì •] ì–¸ì–´ê°€ ì˜ì–´ì¼ ê²½ìš° Routerì—ê²Œ ì§€ì‹œì–´ ì „ë‹¬
            router_input = user_text
            if lang == 'en':
                router_input = f"{user_text} (Please respond in English)"
            
            response_data = await asyncio.to_thread(router.handle, router_input)
        
        payload = format_response_payload(response_data)
        await sio.emit('command-response', payload, to=sid)
        print(f"ğŸ“¤ ì „ì†¡: {payload}")
    except Exception as e:
        print(f"ğŸš¨ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
        await sio.emit('command-response', {"text": sys_msg["process_error"], "type": "error"}, to=sid)

@sio.on('action-confirm')
async def handle_action_confirm(sid, data):
    print(f"ğŸ”˜ ë²„íŠ¼ í´ë¦­ ìˆ˜ì‹  (YES): {data}")
    lang = data.get('lang', 'ko')
    sys_msg = SYSTEM_MESSAGES.get(lang, SYSTEM_MESSAGES["ko"])

    router = get_or_create_router(sid)
    if not router: return
    try:
        with PerformanceTimer("í™•ì¸ ëª…ë ¹ ì²˜ë¦¬ (Router)"):
            # [í•µì‹¬ ìˆ˜ì •] ê¸ì • ë‹µë³€ë„ ì–¸ì–´ì— ë§ê²Œ ë³€í™˜ ë° ì§€ì‹œì–´ ì¶”ê°€
            confirm_text = "Yes" if lang == "en" else "ë„¤"
            if lang == 'en':
                confirm_text += " (Please respond in English)"
            
            response_data = await asyncio.to_thread(router.handle, confirm_text)
        
        payload = format_response_payload(response_data)
        await sio.emit('command-response', payload, to=sid)
    except Exception as e:
        print(f"ğŸš¨ ì‹¤í–‰ ì¤‘ ì—ëŸ¬: {e}")
        await sio.emit('command-response', {"text": sys_msg["exec_error"], "type": "error"}, to=sid)

@sio.on('audio-upload')
async def handle_audio_upload(sid, data):
    print(f"ğŸ¤ ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  ({sid})")
    total_timer = PerformanceTimer("ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì „ì²´ (Total Flow)")
    total_timer.__enter__()

    # 1. ì–¸ì–´ ë° ì„¤ì • ë¡œë“œ
    lang = data.get('lang', 'ko')
    if lang not in KEYWORDS: lang = "ko"
    
    current_keywords = KEYWORDS[lang]
    sys_msg = SYSTEM_MESSAGES[lang]
    # HuggingFace WhisperëŠ” 'korean', 'english' ë“±ìœ¼ë¡œ í’€ë„¤ì„ ì‚¬ìš© ê¶Œì¥
    whisper_lang_code = current_keywords["whisper_lang"] 

    router = get_or_create_router(sid)
    if not router: 
        total_timer.__exit__(None, None, None)
        return

    # ì„ì‹œ íŒŒì¼ ê²½ë¡œ ë³€ìˆ˜ ì´ˆê¸°í™”
    temp_raw_path = None
    temp_wav_path = None

    # ì „ì—­ ëª¨ë¸ ì»¨í…Œì´ë„ˆ ì°¸ì¡°
    models = global_models 

    try:
        # ------------------------------------------------------------------
        # 1. íŒŒì¼ ì €ì¥ ë° ì „ì²˜ë¦¬ (Tempfile ì‚¬ìš©ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´)
        # ------------------------------------------------------------------
        with PerformanceTimer("1. ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ë° ë³€í™˜"):
            b64_string = data.get('audioData')
            file_ext = data.get('format', 'm4a')
            
            # Base64 ë””ì½”ë”©
            try:
                if not b64_string: raise ValueError("Empty audio data")
                audio_bytes = base64.b64decode(b64_string)
            except Exception:
                print("ğŸš¨ Base64 ë””ì½”ë”© ì‹¤íŒ¨")
                await sio.emit('command-response', {"text": sys_msg["process_error"], "type": "error"}, to=sid)
                return

            # (1) Raw íŒŒì¼ ìƒì„± (ìë™ ì‚­ì œ ë°©ì§€ë¥¼ ìœ„í•´ delete=False, finallyì—ì„œ ì‚­ì œ)
            with tempfile.NamedTemporaryFile(suffix=f".{file_ext}", delete=False) as tmp_raw:
                tmp_raw.write(audio_bytes)
                temp_raw_path = tmp_raw.name
            
            # (2) WAV ë³€í™˜ ëŒ€ìƒ ê²½ë¡œ ìƒì„±
            temp_wav_path = temp_raw_path.replace(f".{file_ext}", "_processed.wav")

            # (3) Pydub ë³€í™˜ (ë¸”ë¡œí‚¹ ì‘ì—…ì´ë¯€ë¡œ ìŠ¤ë ˆë“œ ë¶„ë¦¬)
            def convert_audio():
                audio = AudioSegment.from_file(temp_raw_path, format=file_ext)
                audio = audio.set_channels(1)       # ëª¨ë…¸
                audio = audio.set_frame_rate(16000) # 16kHz (Whisper í‘œì¤€)
                audio = pydub_normalize(audio)      # ë³¼ë¥¨ ì •ê·œí™”
                audio.export(temp_wav_path, format="wav")
                return temp_wav_path

            await asyncio.to_thread(convert_audio)

        # ------------------------------------------------------------------
        # 2. [1ì°¨] Medium ëª¨ë¸ë¡œ ì¼ë°˜ ì¸ì‹ (ìˆœì • ëª¨ë¸ ì‚¬ìš©)
        # ------------------------------------------------------------------
        print(f"ğŸ‘‚ [1ë‹¨ê³„] Medium ëª¨ë¸ ì¸ì‹ (Lang: {whisper_lang_code})...")

        def transcribe_medium():
            # librosaë¡œ ë¡œë“œ (sr=16000)
            audio_array, _ = librosa.load(temp_wav_path, sr=16000) 
            
            # ProcessorëŠ” ê³µìš© ì‚¬ìš© (í† í¬ë‚˜ì´ì € í˜¸í™˜ë¨)
            inputs = models.processor(
                audio_array, 
                sampling_rate=16000, 
                return_tensors="pt"
            ).input_features.to(models.device)
            
            # [1ì°¨] Medium ëª¨ë¸ ì¶”ë¡  (ìˆœì •)
            # stt_model_mediumì€ ìˆœì • WhisperForConditionalGeneration ê°ì²´ì„
            with torch.no_grad():
                outputs = models.stt_model_medium.generate(
                    inputs,
                    language=whisper_lang_code, 
                    max_new_tokens=128,
                    return_dict_in_generate=True, 
                    output_scores=True            
                )
            
            generated_ids = outputs.sequences
            text = models.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
            
            # ì‹ ë¢°ë„(Log Probability) ê³„ì‚°
            transition_scores = models.stt_model_medium.compute_transition_scores(
                outputs.sequences, outputs.scores, normalize_logits=True
            )
            avg_logprob = torch.mean(transition_scores[0]).item()
            
            return text.strip(), avg_logprob

        with PerformanceTimer("3. STT 1ì°¨ (Whisper Medium)"):
            text_std, score_std = await asyncio.to_thread(transcribe_medium)
        
        print(f"ğŸ—£ï¸ [1ì°¨ Medium ê²°ê³¼] '{text_std}' (ì‹ ë¢°ë„: {score_std:.4f})")

        # ------------------------------------------------------------------
        # 3. [íŒë‹¨] ì í•©ë„ ê²€ì‚¬ ë° ë¶„ê¸°
        # ------------------------------------------------------------------
        use_dys_model = False
        # Mediumì€ ì„±ëŠ¥ì´ ì¢‹ìœ¼ë¯€ë¡œ ì„ê³„ê°’ì„ ì¡°ê¸ˆ ë‚®ê²Œ ì¡ì•„ë„ ë¨ (ì˜ˆ: -0.6 ~ -0.7)
        CONFIDENCE_THRESHOLD = -0.6 

        if score_std < CONFIDENCE_THRESHOLD:
            print(f"ğŸ“‰ ì‹ ë¢°ë„ ë‚®ìŒ({score_std:.2f}) -> 2ì°¨ ê²€ì¦ í•„ìš”")
            use_dys_model = True
        elif len(text_std) < 2: 
            print("ğŸ“‰ í…ìŠ¤íŠ¸ ë„ˆë¬´ ì§§ìŒ -> 2ì°¨ ê²€ì¦ í•„ìš”")
            use_dys_model = True

        # ì¤‘ìš” í‚¤ì›Œë“œê°€ 1ì°¨ì—ì„œ ì´ë¯¸ ëª…í™•íˆ ë“¤ë ¸ë‹¤ë©´ 2ì°¨ ìƒëµ (ì˜¤íƒ ë°©ì§€)
        for kw in current_keywords["health"]:
            if kw.lower() in text_std.lower(): use_dys_model = False; break
        for kw in current_keywords["emergency"]:
            if kw.lower() in text_std.lower(): use_dys_model = False; break

        final_text = text_std

        # ------------------------------------------------------------------
        # 4. [2ì°¨] Small + LoRA ëª¨ë¸ë¡œ ì •ë°€ ì¸ì‹ (í•œêµ­ì–´ì¼ ë•Œë§Œ ìˆ˜í–‰)
        # ------------------------------------------------------------------
        if use_dys_model and lang == 'ko': 
            print("ğŸš€ [2ë‹¨ê³„] Small + LoRA ëª¨ë¸ ê°€ë™ (Beam Search)")

            def transcribe_small_lora():
                audio_array, _ = librosa.load(temp_wav_path, sr=16000)
                inputs = models.processor(
                    audio_array, sampling_rate=16000, return_tensors="pt"
                ).input_features.to(models.device)

                # [2ì°¨] Small + LoRA ëª¨ë¸ ì¶”ë¡ 
                # stt_model_small_loraëŠ” PeftModel ê°ì²´ì„
                with torch.no_grad():
                    generated_ids = models.stt_model_small_lora.generate(
                        inputs, 
                        language=whisper_lang_code,
                        num_beams=5,             # ë¹” ì„œì¹˜ë¡œ ì •í™•ë„ í–¥ìƒ
                        num_return_sequences=3,  # ìƒìœ„ 3ê°œ í›„ë³´ ì¶”ì¶œ
                        early_stopping=True
                    )
                return models.processor.batch_decode(generated_ids, skip_special_tokens=True)

            with PerformanceTimer("4. STT 2ì°¨ (Small+LoRA)"):
                candidates = await asyncio.to_thread(transcribe_small_lora)
            
            print(f"ğŸ§ [2ì°¨ í›„ë³´êµ°]: {candidates}")
            
            if candidates:
                final_text = candidates[0] # ê¸°ë³¸ì ìœ¼ë¡œ 1ìˆœìœ„ ì±„íƒ
                
                # í›„ë³´êµ° ì¤‘ ì‘ê¸‰/ê±´ê°• í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ì´ ìˆë‹¤ë©´ ìš°ì„  ì±„íƒ (Rescue Logic)
                for cand in candidates:
                    all_keywords = current_keywords["emergency"] + current_keywords["health"]
                    if any(kw.lower() in cand.lower() for kw in all_keywords):
                        print(f"âœ… í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ í›„ë³´ êµì²´: {cand}")
                        final_text = cand
                        break

        print(f"âœ… ìµœì¢… í™•ì •: \"{final_text}\"")

        # ------------------------------------------------------------------
        # 5. ê²°ê³¼ ì²˜ë¦¬ ë° ë¼ìš°í„° ì „ë‹¬
        # ------------------------------------------------------------------
        
        # ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
        if not final_text:
            await sio.emit('command-response', {"text": sys_msg["not_heard"], "type": "simple"}, to=sid)
            return

        # ì‚¬ìš©ìì—ê²Œ ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì „ì†¡ (ì±„íŒ…ì°½ í‘œì‹œìš©)
        await sio.emit('user-speech', {'text': final_text}, to=sid)

        # ë¹„ìƒ ì •ì§€ í‚¤ì›Œë“œ ì²´í¬ (ìµœìš°ì„  ìˆœìœ„)
        if any(kw.lower() in final_text.lower() for kw in current_keywords["emergency"]):
            await execute_emergency_stop(sid, data.get('userId', 'unknown'), lang)
            return

        # Router ëª…ë ¹ ì²˜ë¦¬
        with PerformanceTimer("5. Router ëª…ë ¹ ì²˜ë¦¬"):
            # ì–¸ì–´ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ì¡°ì • (í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©)
            router_input = build_prompt_with_lang(final_text, lang)
            
            response_data = await asyncio.to_thread(router.handle, router_input)
        
        payload = format_response_payload(response_data)
        await sio.emit('command-response', payload, to=sid)

    except Exception as e:
        print(f"ğŸš¨ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
        import traceback; traceback.print_exc()
        await sio.emit('command-response', {"text": sys_msg["process_error"], "type": "error"}, to=sid)
    
    finally:
        # ------------------------------------------------------------------
        # 6. ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ë°˜ë“œì‹œ ìˆ˜í–‰)
        # ------------------------------------------------------------------
        try:
            if temp_raw_path and os.path.exists(temp_raw_path):
                os.remove(temp_raw_path)
            if temp_wav_path and os.path.exists(temp_wav_path):
                os.remove(temp_wav_path)
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        total_timer.__exit__(None, None, None)

@sio.on('identify-face')
async def handle_identify_face(sid, data):
    print(f"ğŸ“¸ {sid} ì–¼êµ´ ì¸ì‹ ìš”ì²­ ìˆ˜ì‹ ")
    
    # [ìˆ˜ì •] ë°ì´í„° íŒŒì‹± (í´ë¼ì´ì–¸íŠ¸ê°€ ê°ì²´ë¡œ ë³´ë‚¼ ë•Œì™€ ë¬¸ìì—´ë¡œ ë³´ë‚¼ ë•Œ ëª¨ë‘ ëŒ€ì‘)
    lang = "ko"
    base64_image = ""

    if isinstance(data, dict):
        base64_image = data.get('image', '')
        lang = data.get('lang', 'ko')
    else:
        # ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ í˜¸í™˜ì„± ìœ ì§€ (ë¬¸ìì—´ë§Œ ì˜¨ ê²½ìš°)
        base64_image = data
        lang = "ko"

    try:
        with PerformanceTimer("ì´ë¯¸ì§€ ë””ì½”ë”©"):
            img = await asyncio.to_thread(decode_image, base64_image)
        
        if img is None:
            await sio.emit('auth-fail', {"reason": "image_decode_error"}, to=sid)
            return
        
        # [Mock] ì–¼êµ´ ì¸ì‹ ë¡œì§ (ê°€ì •)
        await asyncio.sleep(0.5)
        
        # [í•µì‹¬ ìˆ˜ì •] ì–¸ì–´ì— ë”°ë¥¸ ì´ë¦„ ë¶„ê¸° ì²˜ë¦¬
        if lang == 'en':
            user_name = "KimVla"
        else:
            user_name = "ê¹€ë¸”ë¼"
            
        user = {"id": "p123", "name": user_name}
        
        print(f"âœ… ì¸ì¦ ì„±ê³µ: {user_name} ({lang})")
        await sio.emit('auth-success', user, to=sid)
        
    except Exception as e:
        print(f"ğŸš¨ ì¸ì¦ ì˜¤ë¥˜: {e}")
        await sio.emit('auth-fail', to=sid)

if __name__ == "__main__":
    print(f"ğŸš€ AI Router ì„œë²„ ì‹œì‘ (Port: {PORT})")
    uvicorn.run(app, host="0.0.0.0", port=PORT)